# LightRail AI Environment Configuration
# Copy this file to .env.local and fill in your values

# ===========================================
# LLM API Keys (at least one required)
# ===========================================

# Google Gemini API Key (recommended)
VITE_GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API Key (alternative)
VITE_OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (alternative)
VITE_ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ===========================================
# Optional: Local LLM Configuration
# ===========================================

# Local LLM URL (e.g., Ollama)
VITE_LOCAL_LLM_URL=http://localhost:11434

# ===========================================
# Application Settings
# ===========================================

# Log level: debug, info, warn, error, silent
VITE_LOG_LEVEL=info

# Enable debug mode
VITE_ENABLE_DEBUG=false

# Enable telemetry
VITE_ENABLE_TELEMETRY=false

# API base URL (for backend services)
VITE_API_BASE_URL=http://localhost:3000

# ===========================================
# Optional: Remote Logging
# ===========================================

# Enable remote logging
VITE_ENABLE_REMOTE_LOGGING=false

# Remote log endpoint
VITE_LOG_ENDPOINT=
